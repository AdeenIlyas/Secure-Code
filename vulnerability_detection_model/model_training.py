import pickle  # Object serialization
from tensorflow.keras.models import Sequential  # Sequential model
# Neural network layers
from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping  # Early stopping callback
from sklearn.metrics import classification_report  # Classification metrics
from tensorflow.keras.models import load_model  # Model loading

X_train, y_train = pickle.load(
    open('train_data.pkl', 'rb'))  # Load training data
X_val, y_val = pickle.load(open('val_data.pkl', 'rb'))  # Load validation data
X_test, y_test = pickle.load(open('test_data.pkl', 'rb'))  # Load test data

model = Sequential([  # Create sequential model
    Embedding(input_dim=5000, output_dim=128,
              input_length=500),  # Embedding layer
    Conv1D(128, 5, activation='relu'),  # 1D convolution layer
    GlobalMaxPooling1D(),  # Global max pooling
    Dropout(0.5),  # Dropout for regularization
    Dense(64, activation='relu'),  # Dense layer
    Dropout(0.3),  # Dropout for regularization
    Dense(1, activation='sigmoid')  # Output layer
])

model.compile(optimizer='adam', loss='binary_crossentropy',
              metrics=['accuracy'])  # Compile model

early_stop = EarlyStopping(
    monitor='val_loss', patience=3, restore_best_weights=True)  # Early stopping

model.fit(X_train, y_train,  # Train model
          epochs=10,  # Number of epochs
          batch_size=32,  # Batch size
          validation_data=(X_val, y_val),  # Validation data
          callbacks=[early_stop])  # Callbacks

# Evaluate the model
y_pred = (model.predict(X_test) > 0.5).astype("int32")  # Make predictions

# Print classification report
print("Classification Report:\n", classification_report(
    y_test, y_pred, digits=4))  # Print metrics

# Save the trained model
model.save('cnn_vulnerability_classifier.h5')  # Save model
print("Model saved as 'cnn_vulnerability_classifier.h5'")  # Confirmation message
